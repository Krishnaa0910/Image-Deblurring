{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishnaa0910/Image-Deblurring/blob/main/Deblur_Hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aa1bb21",
      "metadata": {
        "id": "7aa1bb21"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "dataset_path = r'D:\\deblur\\GoPro'\n",
        "\n",
        "def load_images(dataset_path, img_size=(256, 256)):\n",
        "    blur_images = []\n",
        "    sharp_images = []\n",
        "\n",
        "    blur_path = os.path.join(dataset_path, \"train\", \"input/input\")\n",
        "    sharp_path = os.path.join(dataset_path, \"train\", \"target/target\")\n",
        "\n",
        "    for img in os.listdir(blur_path):\n",
        "        blur_img = cv2.imread(os.path.join(blur_path, img))\n",
        "        if blur_img is None:\n",
        "            continue\n",
        "        blur_img = cv2.resize(blur_img, img_size)\n",
        "        blur_img = blur_img.astype(np.float32) / 255.0\n",
        "        blur_images.append(blur_img)\n",
        "\n",
        "        sharp_img = cv2.imread(os.path.join(sharp_path, img))\n",
        "        if sharp_img is None:\n",
        "            continue\n",
        "        sharp_img = cv2.resize(sharp_img, img_size)\n",
        "        sharp_img = sharp_img.astype(np.float32) / 255.0\n",
        "        sharp_images.append(sharp_img)\n",
        "\n",
        "    return np.array(blur_images), np.array(sharp_images)\n",
        "\n",
        "# Loading images\n",
        "blur_images, sharp_images = load_images(dataset_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb067fbe",
      "metadata": {
        "id": "eb067fbe",
        "outputId": "62974499-c4ab-40aa-8035-33a675691d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      4864      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 128)     204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       409728    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 128)       409728    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 64, 64, 128)      409728    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 128, 128, 128)    409728    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128, 128, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 256, 256, 128)    409728    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256, 256, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 256, 256, 3)       9603      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,271,363\n",
            "Trainable params: 2,269,699\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 128, 128, 64)      4864      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 64, 64, 128)       204928    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 128)       409728    \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       409728    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 1)         3201      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 16, 16, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,032,449\n",
            "Trainable params: 1,032,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " model (Functional)          (None, 256, 256, 3)       2271363   \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 16, 16, 1)         1032449   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,303,812\n",
            "Trainable params: 2,269,699\n",
            "Non-trainable params: 1,034,113\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def srn_generator(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoding layers\n",
        "    x = Conv2D(64, kernel_size=5, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Several more convolutional layers for downsampling\n",
        "    for _ in range(3):\n",
        "        x = Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    # Decoding layers\n",
        "    for _ in range(3):\n",
        "        x = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    outputs = Conv2D(3, kernel_size=5, strides=1, padding='same', activation='tanh')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "generator = srn_generator()\n",
        "generator.summary()\n",
        "\n",
        "def build_discriminator(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=5, strides=2, padding='same')(inputs)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    for _ in range(3):\n",
        "        x = Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(1, kernel_size=5, strides=1, padding='same')(x)\n",
        "    outputs = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(256, 256, 3))\n",
        "    deblurred_image = generator(gan_input)\n",
        "    gan_output = discriminator(deblurred_image)\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    return gan\n",
        "\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.summary()\n",
        "\n",
        "# Compile the models\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "generator.compile(loss='mse', optimizer=optimizer)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f75e5bc",
      "metadata": {
        "id": "1f75e5bc",
        "outputId": "d13242ab-8a4c-4aa0-85cc-fff0db9c5a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "0 [D loss: 0.6982899308204651] [G loss: 0.6979234218597412]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "10 [D loss: 0.6981483399868011] [G loss: 0.5006316900253296]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "20 [D loss: 0.7015767693519592] [G loss: 0.4856358766555786]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "30 [D loss: 0.7052323818206787] [G loss: 0.47640711069107056]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "40 [D loss: 0.7104310095310211] [G loss: 0.46955791115760803]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "50 [D loss: 0.7154340147972107] [G loss: 0.46480605006217957]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "60 [D loss: 0.7219273746013641] [G loss: 0.46182262897491455]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "70 [D loss: 0.7286078929901123] [G loss: 0.4602805972099304]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "80 [D loss: 0.7369453608989716] [G loss: 0.45664021372795105]\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "90 [D loss: 0.74449422955513] [G loss: 0.4532071650028229]\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "100 [D loss: 0.7535442113876343] [G loss: 0.4509408473968506]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 101\n",
        "batch_size = 8\n",
        "real_label = np.ones((batch_size, 16, 16, 1))\n",
        "fake_label = np.zeros((batch_size, 16, 16, 1))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training Discriminator\n",
        "    idx = np.random.randint(0, blur_images.shape[0], batch_size)\n",
        "    real_imgs = sharp_images[idx]\n",
        "    blur_imgs = blur_images[idx]\n",
        "\n",
        "    fake_imgs = generator.predict(blur_imgs)\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_imgs, real_label)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    g_loss = gan.train_on_batch(blur_imgs, real_label)\n",
        "\n",
        "    if epoch % 10 == 0:  # Prints every 10 epochs\n",
        "        print(f\"{epoch} [D loss: {d_loss}] [G loss: {g_loss}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11cf97e4",
      "metadata": {
        "id": "11cf97e4",
        "outputId": "e6641c9b-e59b-4a05-e869-1e73746ffb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 256, 256, 64)      4864      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 256, 256, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 128, 128, 128)     204928    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128, 128, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 64, 64, 128)       409728    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 32, 128)       409728    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 128)      409728    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 64, 64, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 128, 128, 128)    409728    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 128, 128, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 256, 256, 128)    409728    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 256, 256, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 256, 256, 3)       9603      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,271,363\n",
            "Trainable params: 2,269,699\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def srn_generator(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoding layers\n",
        "    x = Conv2D(64, kernel_size=5, strides=1, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Several more convolutional layers for downsampling\n",
        "    for _ in range(3):\n",
        "        x = Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    # Decoding layers\n",
        "    for _ in range(3):\n",
        "        x = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    outputs = Conv2D(3, kernel_size=5, strides=1, padding='same', activation='tanh')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "generator = srn_generator()\n",
        "generator.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16384401",
      "metadata": {
        "id": "16384401",
        "outputId": "adaf6018-ab93-4bac-b15d-01979515b44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 128, 128, 64)      4864      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 128)       204928    \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 128)       409728    \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 128)       409728    \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 1)         3201      \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 16, 16, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,032,449\n",
            "Trainable params: 1,032,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_discriminator(input_shape=(256, 256, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=5, strides=2, padding='same')(inputs)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    for _ in range(3):\n",
        "        x = Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(1, kernel_size=5, strides=1, padding='same')(x)\n",
        "    outputs = Activation('sigmoid')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9caf0040",
      "metadata": {
        "id": "9caf0040",
        "outputId": "01906ace-7298-47db-90d7-35657d01ef56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " model_3 (Functional)        (None, 256, 256, 3)       2271363   \n",
            "                                                                 \n",
            " model_4 (Functional)        (None, 16, 16, 1)         1032449   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,303,812\n",
            "Trainable params: 2,269,699\n",
            "Non-trainable params: 1,034,113\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(256, 256, 3))\n",
        "    deblurred_image = generator(gan_input)\n",
        "    gan_output = discriminator(deblurred_image)\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    return gan\n",
        "\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}